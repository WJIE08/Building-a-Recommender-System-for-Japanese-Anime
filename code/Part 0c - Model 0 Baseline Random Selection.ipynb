{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"**This set of codes looks at a recommendation that is based on random selection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import timeit\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Processed Anime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 4808 rows and 92 columns\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data/processed_anime.csv\")\n",
    "print('Data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4808 entries, 0 to 4807\n",
      "Data columns (total 92 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   index                4808 non-null   int64  \n",
      " 1   Unnamed: 0           4808 non-null   int64  \n",
      " 2   Unnamed: 0.1         4808 non-null   int64  \n",
      " 3   Title                4808 non-null   object \n",
      " 4   URL                  4808 non-null   object \n",
      " 5   English              2862 non-null   object \n",
      " 6   Synonyms             3075 non-null   object \n",
      " 7   Japanese             4801 non-null   object \n",
      " 8   Type                 4808 non-null   object \n",
      " 9   Episodes             4585 non-null   float64\n",
      " 10  Status               4808 non-null   object \n",
      " 11  Aired                4808 non-null   object \n",
      " 12  Premiered            4808 non-null   object \n",
      " 13  Broadcast            4808 non-null   object \n",
      " 14  Producers            4808 non-null   object \n",
      " 15  Licensors            4808 non-null   object \n",
      " 16  Studios              4808 non-null   object \n",
      " 17  Source               4808 non-null   object \n",
      " 18  Genres               4808 non-null   object \n",
      " 19  Duration             4808 non-null   int64  \n",
      " 20  Rating               4808 non-null   object \n",
      " 21  Score                3820 non-null   float64\n",
      " 22  Ranked               4659 non-null   object \n",
      " 23  Popularity           4808 non-null   object \n",
      " 24  Members              4808 non-null   int64  \n",
      " 25  Favorites            4808 non-null   int64  \n",
      " 26  Started              4745 non-null   object \n",
      " 27  Ended                4699 non-null   object \n",
      " 28  Voters               3820 non-null   float64\n",
      " 29  Adaptation           2652 non-null   object \n",
      " 30  Alternative version  496 non-null    object \n",
      " 31  Side story           888 non-null    object \n",
      " 32  Spin-off             243 non-null    object \n",
      " 33  Synopsis             4808 non-null   object \n",
      " 34  Prequel              1202 non-null   object \n",
      " 35  Alternative setting  195 non-null    object \n",
      " 36  Sequel               1505 non-null   object \n",
      " 37  Other                718 non-null    object \n",
      " 38  Summary              382 non-null    object \n",
      " 39  Character            149 non-null    object \n",
      " 40  Parent story         63 non-null     object \n",
      " 41  Full story           4 non-null      object \n",
      " 42  Genre_0              4808 non-null   object \n",
      " 43  Genre_1              4373 non-null   object \n",
      " 44  Genre_2              3488 non-null   object \n",
      " 45  Genre_3              2381 non-null   object \n",
      " 46  Genre_4              1318 non-null   object \n",
      " 47  Genre_5              571 non-null    object \n",
      " 48  Genre_6              222 non-null    object \n",
      " 49  Genre_7              80 non-null     object \n",
      " 50  Genre_8              35 non-null     object \n",
      " 51  Genre_9              11 non-null     object \n",
      " 52  Genre_10             1 non-null      object \n",
      " 53  Genre_11             0 non-null      float64\n",
      " 54  Genre_12             0 non-null      float64\n",
      " 55  Air_Start            4745 non-null   object \n",
      " 56  Air_End              4461 non-null   object \n",
      " 57  Duration_Aired       4461 non-null   float64\n",
      " 58  Producer_0           3612 non-null   object \n",
      " 59  Producer_1           2316 non-null   object \n",
      " 60  Producer_2           1561 non-null   object \n",
      " 61  Producer_3           1101 non-null   object \n",
      " 62  Producer_4           781 non-null    object \n",
      " 63  Producer_5           528 non-null    object \n",
      " 64  Producer_6           335 non-null    object \n",
      " 65  Producer_7           207 non-null    object \n",
      " 66  Producer_8           130 non-null    object \n",
      " 67  Producer_9           61 non-null     object \n",
      " 68  Producer_10          34 non-null     object \n",
      " 69  Producer_11          15 non-null     object \n",
      " 70  Producer_12          5 non-null      object \n",
      " 71  Producer_13          2 non-null      object \n",
      " 72  Producer_14          1 non-null      object \n",
      " 73  Producer_15          1 non-null      object \n",
      " 74  Producer_16          1 non-null      object \n",
      " 75  Producer_17          0 non-null      float64\n",
      " 76  Producer_18          0 non-null      float64\n",
      " 77  Producer_19          0 non-null      float64\n",
      " 78  Studio_0             4067 non-null   object \n",
      " 79  Studio_1             342 non-null    object \n",
      " 80  Studio_2             20 non-null     object \n",
      " 81  Studio_3             0 non-null      float64\n",
      " 82  Studio_4             0 non-null      float64\n",
      " 83  Studio_5             0 non-null      float64\n",
      " 84  Studio_6             0 non-null      float64\n",
      " 85  Anime_Number         4808 non-null   int64  \n",
      " 86  Dominant_Topic       4808 non-null   float64\n",
      " 87  Topic_Perc_Contrib   4808 non-null   float64\n",
      " 88  Keywords             4808 non-null   object \n",
      " 89  Text                 4808 non-null   object \n",
      " 90  Topic_Category       4808 non-null   object \n",
      " 91  anime_uid            4808 non-null   int64  \n",
      "dtypes: float64(15), int64(8), object(69)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate dataset\n",
    "df_n = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Hit Rate @ 10 based on Random Selection of Animes to be Recommended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75921, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review = pd.read_csv('processed_data/processed_reviews.csv')\n",
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'profile', 'anime_uid', 'text', 'score', 'scores', 'link'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    75921.000000\n",
       "mean     7.353038    \n",
       "std      2.219829    \n",
       "min      0.000000    \n",
       "25%      6.000000    \n",
       "50%      8.000000    \n",
       "75%      9.000000    \n",
       "max      10.000000   \n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of ratings\n",
    "df_review['score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Train Test Split**\n",
    "\n",
    "Apply the leave-one-out methodology to do train-test split. For each user, the most recent review is used as the test set. The most recent review is indicated by the larger uid. The reamining ratings would be used in the train dataset. This will help to ensure no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15363, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataset\n",
    "test = df_review.loc[df_review.groupby('profile')['uid'].idxmax()]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60558, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train dataset\n",
    "train = df_review[~(df_review['uid'].isin(test['uid'].tolist()))]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Identify animes which have been watched by users as well as those which have not been watched by users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique list of anime_uid\n",
    "anime_uid = list(set(df['anime_uid']))\n",
    "len(anime_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15363"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique list of profiles from train dataset\n",
    "profile_list = list(set(train['profile'].tolist()))\n",
    "len(profile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify list of animes watched \n",
    "# identify the list of animes not watched. As the not watched list is huge, \n",
    "# we randomly sample 99 animes not watched items + the one watched item in the test data to form the not watched list.\n",
    "# we repeat this random sampling 10 times to ensure robustness while accounting for limited computational resource.\n",
    "\n",
    "watched_list = []\n",
    "not_watched_list_1 = []\n",
    "not_watched_list_2 = []\n",
    "not_watched_list_3 = []\n",
    "not_watched_list_4 = []\n",
    "not_watched_list_5 = []\n",
    "\n",
    "for user in profile_list:\n",
    "    \n",
    "    # subset watched animes - i.e. those with ratings\n",
    "    u_watched = train[train['profile']==user]['anime_uid'].tolist()\n",
    "    watched_list.append(u_watched)\n",
    "    \n",
    "    # identify animes not watched i.e. those without ratings\n",
    "    u_not_watched = list(set(anime_uid) - set(u_watched) - set(test[test['profile']==user]['anime_uid'].tolist()))\n",
    "    \n",
    "    # set seed to control reproducibility of sampling\n",
    "    random.seed(2345)\n",
    "    u_not_watched_1 = random.sample(u_not_watched, 99) + test[test['profile']==user]['anime_uid'].tolist()\n",
    "    not_watched_list_1.append(u_not_watched_1)\n",
    "    \n",
    "    random.seed(2346)\n",
    "    u_not_watched_2 = random.sample(u_not_watched, 99) + test[test['profile']==user]['anime_uid'].tolist()\n",
    "    not_watched_list_2.append(u_not_watched_2)\n",
    "    \n",
    "    random.seed(2347)\n",
    "    u_not_watched_3 = random.sample(u_not_watched, 99) + test[test['profile']==user]['anime_uid'].tolist()\n",
    "    not_watched_list_3.append(u_not_watched_3)\n",
    "    \n",
    "    random.seed(2348)\n",
    "    u_not_watched_4 = random.sample(u_not_watched, 99) + test[test['profile']==user]['anime_uid'].tolist()\n",
    "    not_watched_list_4.append(u_not_watched_4)\n",
    "    \n",
    "    random.seed(2349)\n",
    "    u_not_watched_5 = random.sample(u_not_watched, 99) + test[test['profile']==user]['anime_uid'].tolist()\n",
    "    not_watched_list_5.append(u_not_watched_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15363\n",
      "15363\n",
      "15363\n"
     ]
    }
   ],
   "source": [
    "# check len of watched_list and not watched list\n",
    "print(len(watched_list))\n",
    "print(len(not_watched_list_1))\n",
    "print(len(not_watched_list_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# check \n",
    "print(len(watched_list[0]))\n",
    "print(len(not_watched_list_1[0]))\n",
    "print(len(not_watched_list_5[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Randomly Select Animes to be Recommended to each user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute the predicted ratings for not watched list for each user\n",
    "\n",
    "def get_recommends(profile, not_watched, train_dataset):\n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        profile - list of unique profiles\n",
    "        not_watched - list of not watched animes for all users\n",
    "        train_dataset - train data\n",
    "    \n",
    "    Returns:\n",
    "        recommend - list of 10 recommended animes\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # initialise list to store predictions\n",
    "    recommend = []\n",
    "    \n",
    "    for i in range(len(profile)):\n",
    "        \n",
    "        anime_list = not_watched[i]\n",
    "        \n",
    "        recommend_idx = np.random.randint(100, size=10)\n",
    "        recommended_animes = [anime_list[idx] for idx in recommend_idx]\n",
    "        recommend.append(recommended_animes)\n",
    "        \n",
    "    return recommend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "Time taken: 1.7177855999999565\n"
     ]
    }
   ],
   "source": [
    "# Generate recommended items for each user\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "recommended_1 = get_recommends(profile_list, not_watched_list_1, train)\n",
    "print('done')\n",
    "recommended_2 = get_recommends(profile_list, not_watched_list_2, train)\n",
    "print('done')\n",
    "recommended_3 = get_recommends(profile_list, not_watched_list_3, train)\n",
    "print('done')\n",
    "recommended_4 = get_recommends(profile_list, not_watched_list_4, train)\n",
    "print('done')\n",
    "recommended_5 = get_recommends(profile_list, not_watched_list_5, train)\n",
    "print('done')\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Time taken:', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40357, 40357, 10578, 33245, 148, 36740, 39960, 38161, 2921, 33850]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "recommended_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Evaluate Hit Rate @ 10 for Proposed Recommender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to evaluate hit rate @ 10\n",
    "\n",
    "def hit_rate(animes_rec, test_dataset, profile):\n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        animes_rec - the nest list of top 10 recommended animes for each user \n",
    "        test_dataset - test data\n",
    "        profile - list of unique profiles\n",
    "    \n",
    "    Returns:\n",
    "        hit_rate - hit rate @ 10\n",
    "    '''\n",
    "    \n",
    "    hit = 0\n",
    "    \n",
    "    for i in range(len(animes_rec)):\n",
    "    \n",
    "        user = profile[i]\n",
    "        \n",
    "        recommended_animes = animes_rec[i]\n",
    "    \n",
    "        # check if the test data is found in the randomly selected top 10 recommended animes\n",
    "        anime_watched = test_dataset[test_dataset['profile']==user]['anime_uid']\n",
    "\n",
    "        if anime_watched.values in recommended_animes:\n",
    "            hit += 1\n",
    "        else:\n",
    "            hit = hit\n",
    "    \n",
    "    hit_rate = round((hit/len(profile))*100,2)\n",
    "    \n",
    "    return hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 85.18538860000001\n"
     ]
    }
   ],
   "source": [
    "# Generate hit rate @ 10 for the different samples\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "hit_rate_1 = hit_rate(recommended_1, test, profile_list)\n",
    "hit_rate_2 = hit_rate(recommended_2, test, profile_list)\n",
    "hit_rate_3 = hit_rate(recommended_3, test, profile_list)\n",
    "hit_rate_4 = hit_rate(recommended_4, test, profile_list)\n",
    "hit_rate_5 = hit_rate(recommended_5, test, profile_list)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Time taken:', elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate @ 10 based on not_watched_list_1: 9.71%\n",
      "Hit Rate @ 10 based on not_watched_list_2: 9.54%\n",
      "Hit Rate @ 10 based on not_watched_list_3: 9.55%\n",
      "Hit Rate @ 10 based on not_watched_list_4: 9.67%\n",
      "Hit Rate @ 10 based on not_watched_list_5: 9.59%\n"
     ]
    }
   ],
   "source": [
    "# print hit rates\n",
    "print('Hit Rate @ 10 based on not_watched_list_1: {}%'.format(hit_rate_1))\n",
    "print('Hit Rate @ 10 based on not_watched_list_2: {}%'.format(hit_rate_2))\n",
    "print('Hit Rate @ 10 based on not_watched_list_3: {}%'.format(hit_rate_3))\n",
    "print('Hit Rate @ 10 based on not_watched_list_4: {}%'.format(hit_rate_4))\n",
    "print('Hit Rate @ 10 based on not_watched_list_5: {}%'.format(hit_rate_5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Hit Rate @ 10 based on the 5 different sets of randomly sampled not watched list: 9.612%\n"
     ]
    }
   ],
   "source": [
    "# print avg hit rates\n",
    "avg_hit_rate = (hit_rate_1 + hit_rate_2 + hit_rate_3 + hit_rate_4 + hit_rate_5)/5 \n",
    "print('Average Hit Rate @ 10 based on the 5 different sets of randomly sampled not watched list: {}%'.format(avg_hit_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
